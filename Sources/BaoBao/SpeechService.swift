import Foundation
import AVFoundation
import os.log

/// è¯­éŸ³åˆæˆé”™è¯¯
enum SpeechSynthesisError: Error {
    case apiKeyMissing
    case requestFailed(Error)
    case invalidResponse
    case audioProcessingFailed
    case fileSaveFailed
    case invalidVoiceType
    case customVoiceTrainingFailed
    case customVoiceNotAllowed
    case custom(String)
    
    var localizedDescription: String {
        switch self {
        case .apiKeyMissing:
            return "ç¼ºå°‘Azureè¯­éŸ³æœåŠ¡å¯†é’¥"
        case .requestFailed(let error):
            return "è¯·æ±‚å¤±è´¥: \(error.localizedDescription)"
        case .invalidResponse:
            return "æ— æ•ˆçš„APIå“åº”"
        case .audioProcessingFailed:
            return "éŸ³é¢‘å¤„ç†å¤±è´¥"
        case .fileSaveFailed:
            return "éŸ³é¢‘æ–‡ä»¶ä¿å­˜å¤±è´¥"
        case .invalidVoiceType:
            return "æ— æ•ˆçš„è¯­éŸ³ç±»å‹"
        case .customVoiceTrainingFailed:
            return "è‡ªå®šä¹‰è¯­éŸ³è®­ç»ƒå¤±è´¥"
        case .customVoiceNotAllowed:
            return "å½“å‰è®¾ç½®ä¸å…è®¸è‡ªå®šä¹‰è¯­éŸ³è®­ç»ƒ"
        case .custom(let message):
            return message
        }
    }
}

/// è¯­éŸ³ç±»å‹
enum VoiceType: String, CaseIterable {
    case female = "zh-CN-XiaoxiaoNeural"     // å¥³å£°-å°å­©
    case male = "zh-CN-YunxiNeural"          // ç”·å£°-å°å­©
    case adult_female = "zh-CN-XiaochenNeural" // æˆäººå¥³å£°
    case adult_male = "zh-CN-YunjianNeural"   // æˆäººç”·å£°
    case custom = "custom"                    // è‡ªå®šä¹‰å£°éŸ³
    
    /// æ˜¾ç¤ºåç§°
    var displayName: String {
        switch self {
        case .female: return "å°å¥³å­©"
        case .male: return "å°ç”·å­©"
        case .adult_female: return "æˆäººå¥³å£°"
        case .adult_male: return "æˆäººç”·å£°"
        case .custom: return "è‡ªå®šä¹‰å£°éŸ³"
        }
    }
}

/// è¯­é€Ÿ
enum SpeechRate: String, CaseIterable {
    case slow = "slow"
    case normal = "normal"
    case fast = "fast"
    
    /// æ˜¾ç¤ºåç§°
    var displayName: String {
        switch self {
        case .slow: return "æ…¢é€Ÿ"
        case .normal: return "æ­£å¸¸"
        case .fast: return "å¿«é€Ÿ"
        }
    }
    
    /// SSMLå€¼
    var value: String {
        switch self {
        case .slow: return "0.8"
        case .normal: return "1.0"
        case .fast: return "1.2"
        }
    }
}

/// è¯­éŸ³åˆæˆæœåŠ¡
class SpeechService {
    /// å…±äº«å®ä¾‹
    static let shared = SpeechService()
    
    /// æ—¥å¿—è®°å½•å™¨
    private let logger = Logger(subsystem: "com.example.baobao", category: "SpeechService")
    
    /// éŸ³é¢‘æ’­æ”¾å™¨
    private var audioPlayer: AVAudioPlayer?
    
    /// æœ¬åœ°åˆæˆå™¨ï¼ˆå¤‡ç”¨ï¼‰
    private var localSynthesizer: AVSpeechSynthesizer
    
    /// æœ¬åœ°å½“å‰åˆæˆä»»åŠ¡
    private var currentSynthesisTask: AVSpeechSynthesisTask?
    
    /// æ’­æ”¾è®¡æ—¶å™¨
    private var playbackTimer: Timer?
    
    /// å½“å‰æ’­æ”¾æ—¶é—´
    private var currentPlaybackTime: TimeInterval = 0
    
    /// æ’­æ”¾æ›´æ–°å¤„ç†å™¨
    private var playbackUpdateHandler: ((TimeInterval) -> Void)?
    
    /// Azure APIå¯†é’¥
    private let azureApiKey: String
    
    /// AzureåŒºåŸŸ
    private let azureRegion: String
    
    /// è‡ªå®šä¹‰è¯­éŸ³ID
    private var customVoiceId: String?
    
    /// æ˜¯å¦ä½¿ç”¨æœ¬åœ°å¤‡ç”¨æ–¹æ¡ˆ
    private let useLocalFallback: Bool
    
    /// ç¼“å­˜è¿‡æœŸå¤©æ•°
    private let cacheExpiryDays: Int
    
    /// è¯­éŸ³ç¼“å­˜
    private var audioCache = NSCache<NSString, NSData>()
    
    /// å¹¶å‘é˜Ÿåˆ—
    private let synthesisQueue = DispatchQueue(label: "com.example.baobao.speechsynthesis", attributes: .concurrent)
    
    /// è¯­éŸ³åˆæˆè¿›åº¦é€šçŸ¥
    static let speechSynthesisProgressNotification = Notification.Name("SpeechSynthesisProgressNotification")
    
    // å¸¸é‡
    private let azureBaseUrl = "https://{region}.tts.speech.microsoft.com/cognitiveservices/v1"
    private let azureCustomVoiceUrl = "https://{region}.voice.speech.microsoft.com/api/v1/endpoints/custom"
    
    // éŸ³é¢‘è®¾ç½®
    private let audioSettings: [String: Any] = [
        AVFormatIDKey: Int(kAudioFormatMPEG4AAC),
        AVSampleRateKey: 44100.0,
        AVNumberOfChannelsKey: 2,
        AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue
    ]
    
    /// åˆå§‹åŒ–
    private init() {
        localSynthesizer = AVSpeechSynthesizer()
        
        // ä»é…ç½®ç®¡ç†å™¨è·å–é…ç½®
        let config = ConfigurationManager.shared
        self.azureApiKey = config.azureSpeechKey
        self.azureRegion = config.azureSpeechRegion
        self.customVoiceId = config.azureCustomVoiceId
        self.useLocalFallback = config.useLocalFallback
        self.cacheExpiryDays = config.cacheExpiryDays
        
        // è®°å½•åˆå§‹åŒ–ä¿¡æ¯
        if azureApiKey.isEmpty {
            logger.info("ğŸ™ï¸ SpeechServiceåˆå§‹åŒ–ï¼Œæœªé…ç½®Azureè¯­éŸ³æœåŠ¡ï¼Œå°†ä½¿ç”¨æœ¬åœ°è¯­éŸ³")
        } else {
            logger.info("ğŸ™ï¸ SpeechServiceåˆå§‹åŒ–ï¼Œä½¿ç”¨Azureè¯­éŸ³æœåŠ¡ï¼ŒåŒºåŸŸ: \(azureRegion)")
        }
        
        if let customVoiceId = customVoiceId {
            logger.info("ğŸ™ï¸ è‡ªå®šä¹‰è¯­éŸ³IDå·²é…ç½®: \(customVoiceId)")
        }
        
        // è®¾ç½®ç¼“å­˜é™åˆ¶
        audioCache.countLimit = 50
        audioCache.totalCostLimit = 50 * 1024 * 1024 // 50MB
        
        // è®¾ç½®éŸ³é¢‘ä¼šè¯
        setupAudioSession()
    }
    
    /// è®¾ç½®éŸ³é¢‘ä¼šè¯
    private func setupAudioSession() {
        do {
            try AVAudioSession.sharedInstance().setCategory(.playback, mode: .default)
            try AVAudioSession.sharedInstance().setActive(true)
            logger.info("âœ… éŸ³é¢‘ä¼šè¯è®¾ç½®æˆåŠŸ")
        } catch {
            logger.error("âŒ éŸ³é¢‘ä¼šè¯è®¾ç½®å¤±è´¥: \(error.localizedDescription)")
        }
    }
    
    // MARK: - è¯­éŸ³åˆæˆ
    
    /// åˆæˆè¯­éŸ³
    /// - Parameters:
    ///   - text: è¦åˆæˆçš„æ–‡æœ¬
    ///   - voiceType: è¯­éŸ³ç±»å‹ï¼Œé»˜è®¤ä¸ºèèé˜¿å§¨
    ///   - speechRate: è¯­é€Ÿ
    ///   - useCache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
    ///   - completion: å®Œæˆå›è°ƒï¼Œè¿”å›éŸ³é¢‘æ–‡ä»¶URLæˆ–é”™è¯¯
    func synthesize(text: String, voiceType: VoiceType = .female, speechRate: SpeechRate = .normal, useCache: Bool = true, completion: @escaping (Result<URL, Error>) -> Void) {
        // æ£€æŸ¥æ–‡æœ¬æ˜¯å¦ä¸ºç©º
        guard !text.isEmpty else {
            completion(.failure(NSError(domain: "com.example.baobao", code: -1, userInfo: [NSLocalizedDescriptionKey: "æ–‡æœ¬ä¸ºç©º"])))
            return
        }
        
        // ç”Ÿæˆç¼“å­˜é”®
        let cacheKey = "\(text)_\(voiceType.rawValue)_\(speechRate.rawValue)" as NSString
        
        // æ£€æŸ¥ç¼“å­˜
        if useCache, let cachedData = audioCache.object(forKey: cacheKey) as Data? {
            logger.info("ğŸ“‹ ä½¿ç”¨ç¼“å­˜çš„è¯­éŸ³")
            
            // å°†ç¼“å­˜çš„æ•°æ®ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
            do {
                let tempURL = try saveToTempFile(data: cachedData)
                completion(.success(tempURL))
            } catch {
                logger.error("âŒ æ— æ³•ä»ç¼“å­˜ä¿å­˜éŸ³é¢‘: \(error.localizedDescription)")
                completion(.failure(error))
            }
            return
        }
        
        // å–æ¶ˆå½“å‰çš„åˆæˆä»»åŠ¡ï¼ˆå¦‚æœæœ‰ï¼‰
        currentSynthesisTask?.cancel()
        
        // åœ¨åå°é˜Ÿåˆ—ä¸­è¿›è¡Œè¯­éŸ³åˆæˆ
        synthesisQueue.async { [weak self] in
            guard let self = self else { return }
            
            self.logger.info("ğŸ”Š å¼€å§‹åˆæˆè¯­éŸ³ï¼Œæ–‡æœ¬é•¿åº¦: \(text.count)å­—")
            
            // åˆ†æ®µå¤„ç†é•¿æ–‡æœ¬
            if text.count > 1000 {
                self.synthesizeLongSpeech(text: text, voiceType: voiceType, speechRate: speechRate, cacheKey: cacheKey, completion: completion)
                return
            }
            
            // ç”ŸæˆSSML
            let ssml = self.generateSSML(for: text, voiceType: voiceType, speechRate: speechRate)
            
            // å‘é€APIè¯·æ±‚
            self.makeAzureSpeechRequest(ssml: ssml) { result in
                switch result {
                case .success(let data):
                    // ä¿å­˜åˆ°ç¼“å­˜
                    self.audioCache.setObject(data as NSData, forKey: cacheKey)
                    
                    // ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
                    do {
                        let tempURL = try self.saveToTempFile(data: data)
                        DispatchQueue.main.async {
                            self.logger.info("âœ… è¯­éŸ³åˆæˆæˆåŠŸ")
                            completion(.success(tempURL))
                        }
        } catch {
                        DispatchQueue.main.async {
                            self.logger.error("âŒ æ— æ³•ä¿å­˜éŸ³é¢‘æ–‡ä»¶: \(error.localizedDescription)")
                            completion(.failure(error))
                        }
                    }
                    
                case .failure(let error):
                    DispatchQueue.main.async {
                        self.logger.error("âŒ è¯­éŸ³åˆæˆå¤±è´¥: \(error.localizedDescription)")
            completion(.failure(error))
                    }
                }
            }
        }
    }
    
    /// åˆæˆé•¿æ–‡æœ¬è¯­éŸ³
    /// - Parameters:
    ///   - text: é•¿æ–‡æœ¬
    ///   - voiceType: è¯­éŸ³ç±»å‹
    ///   - speechRate: è¯­é€Ÿ
    ///   - cacheKey: ç¼“å­˜é”®
    ///   - completion: å®Œæˆå›è°ƒ
    private func synthesizeLongSpeech(text: String, 
                                     voiceType: VoiceType, 
                                     speechRate: SpeechRate,
                                     cacheKey: NSString,
                                     completion: @escaping (Result<URL, Error>) -> Void) {
        logger.info("ğŸ“ƒ å¼€å§‹å¤„ç†é•¿æ–‡æœ¬ï¼Œåˆ†æ®µåˆæˆ")
        
        // åˆ†æ®µ
        let segments = splitTextIntoNaturalSegments(text)
        let totalSegments = segments.count
        
        logger.info("ğŸ”¢ æ–‡æœ¬å·²åˆ†ä¸º\(totalSegments)æ®µ")
        
        // ç”¨äºå­˜å‚¨æ‰€æœ‰éŸ³é¢‘æ•°æ®
        var audioDataParts: [Data] = []
        var completedSegments = 0
        
        // åˆ›å»ºä¸€ä¸ªè°ƒåº¦ç»„æ¥åŒæ­¥æ‰€æœ‰åˆ†æ®µçš„å¤„ç†
        let dispatchGroup = DispatchGroup()
        
        // é¡ºåºå¤„ç†æ‰€æœ‰åˆ†æ®µ
        for (index, segment) in segments.enumerated() {
            // è¿›å…¥è°ƒåº¦ç»„
            dispatchGroup.enter()
            
            // ç”Ÿæˆè¯¥åˆ†æ®µçš„SSML
            let ssml = generateSSML(for: segment, voiceType: voiceType, speechRate: speechRate)
            
            // åˆæˆè¯¥åˆ†æ®µ
            makeAzureSpeechRequest(ssml: ssml) { [weak self] result in
                guard let self = self else {
                    dispatchGroup.leave()
            return
                }
                
                switch result {
                case .success(let data):
                    // æ·»åŠ åˆ°ç»“æœåˆ—è¡¨
                    audioDataParts.append(data)
                    
                    // æ›´æ–°è¿›åº¦
                    completedSegments += 1
                    
                    // é€šçŸ¥è¿›åº¦æ›´æ–°
                    let progress = Float(completedSegments) / Float(totalSegments)
                    DispatchQueue.main.async {
                        NotificationCenter.default.post(
                            name: SpeechService.speechSynthesisProgressNotification,
                            object: nil,
                            userInfo: ["progress": progress]
                        )
                    }
                    
                    self.logger.info("âœ… å®Œæˆåˆ†æ®µ \(index + 1)/\(totalSegments) - è¿›åº¦: \(Int(progress * 100))%")
                    
                case .failure(let error):
                    self.logger.error("âŒ åˆ†æ®µ \(index + 1) åˆæˆå¤±è´¥: \(error.localizedDescription)")
                    // æˆ‘ä»¬ç»§ç»­å¤„ç†å…¶ä»–åˆ†æ®µï¼Œä½†è®°å½•é”™è¯¯
                }
                
                // ç¦»å¼€è°ƒåº¦ç»„
                dispatchGroup.leave()
            }
            
            // ä¸ºäº†ä¸è¶…è¿‡APIé€Ÿç‡é™åˆ¶ï¼Œåœ¨åˆ†æ®µè¯·æ±‚ä¹‹é—´æ·»åŠ å°å»¶è¿Ÿ
            if index < segments.count - 1 {
                Thread.sleep(forTimeInterval: 0.2)
            }
        }
        
        // æ‰€æœ‰åˆ†æ®µå®Œæˆå
        dispatchGroup.notify(queue: .global()) { [weak self] in
            guard let self = self else { return }
            
            // æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„éŸ³é¢‘æ•°æ®
            guard !audioDataParts.isEmpty else {
                DispatchQueue.main.async {
                    completion(.failure(NSError(domain: "com.example.baobao", code: -1, userInfo: [NSLocalizedDescriptionKey: "æ‰€æœ‰åˆ†æ®µåˆæˆéƒ½å¤±è´¥äº†"])))
                }
                return
            }
            
            // åˆå¹¶æ‰€æœ‰éŸ³é¢‘æ•°æ®
            do {
                let combinedData = try self.mergeAudioData(audioDataParts)
                
                // ä¿å­˜åˆ°ç¼“å­˜
                self.audioCache.setObject(combinedData as NSData, forKey: cacheKey)
                
                // ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
                let tempURL = try self.saveToTempFile(data: combinedData)
                
                DispatchQueue.main.async {
                    self.logger.info("âœ… é•¿æ–‡æœ¬è¯­éŸ³åˆæˆæˆåŠŸ")
                    completion(.success(tempURL))
                }
            } catch {
                DispatchQueue.main.async {
                    self.logger.error("âŒ åˆå¹¶éŸ³é¢‘å¤±è´¥: \(error.localizedDescription)")
                completion(.failure(error))
                }
            }
        }
    }
    
    /// å°†æ–‡æœ¬åˆ†å‰²æˆè‡ªç„¶æ®µè½
    /// - Parameter text: è¦åˆ†å‰²çš„æ–‡æœ¬
    /// - Returns: åˆ†å‰²åçš„æ®µè½æ•°ç»„
    private func splitTextIntoNaturalSegments(_ text: String) -> [String] {
        // é¦–å…ˆæŒ‰æ®µè½åˆ†å‰²
        var paragraphs = text.components(separatedBy: "\n\n")
        
        // å¦‚æœæ²¡æœ‰æ®µè½ï¼Œåˆ™æŒ‰å¥å­åˆ†å‰²
        if paragraphs.count <= 1 {
            paragraphs = text.components(separatedBy: "ã€‚").filter { !$0.isEmpty }.map { $0 + "ã€‚" }
        }
        
        // ç¡®ä¿æ¯ä¸ªæ®µè½ä¸è¶…è¿‡1000å­—ç¬¦
        var segments: [String] = []
        
        for paragraph in paragraphs {
            if paragraph.count <= 1000 {
                segments.append(paragraph)
            } else {
                // æŒ‰å¥å­åˆ†å‰²é•¿æ®µè½
                let sentences = paragraph.components(separatedBy: "ã€‚").filter { !$0.isEmpty }.map { $0 + "ã€‚" }
                var currentSegment = ""
                
                for sentence in sentences {
                    if currentSegment.count + sentence.count <= 1000 {
                        currentSegment += sentence
                    } else {
                        if !currentSegment.isEmpty {
                            segments.append(currentSegment)
                        }
                        currentSegment = sentence
                    }
                }
                
                if !currentSegment.isEmpty {
                    segments.append(currentSegment)
                }
            }
        }
        
        return segments
    }
    
    /// åˆå¹¶å¤šä¸ªéŸ³é¢‘æ•°æ®
    /// - Parameter audioParts: éŸ³é¢‘æ•°æ®æ•°ç»„
    /// - Returns: åˆå¹¶åçš„éŸ³é¢‘æ•°æ®
    private func mergeAudioData(_ audioParts: [Data]) throws -> Data {
        guard !audioParts.isEmpty else {
            throw NSError(domain: "com.example.baobao", code: -1, userInfo: [NSLocalizedDescriptionKey: "æ²¡æœ‰éŸ³é¢‘æ•°æ®å¯åˆå¹¶"])
        }
        
        // å¦‚æœåªæœ‰ä¸€éƒ¨åˆ†ï¼Œç›´æ¥è¿”å›
        if audioParts.count == 1 {
            return audioParts[0]
        }
        
        // åˆ›å»ºä¸´æ—¶æ–‡ä»¶URLs
        var tempURLs: [URL] = []
        for (index, data) in audioParts.enumerated() {
            let filename = "part_\(index).mp3"
            let url = FileManager.default.temporaryDirectory.appendingPathComponent(filename)
            try data.write(to: url)
            tempURLs.append(url)
        }
        
        // ä½¿ç”¨AVAssetExportSessionåˆå¹¶éŸ³é¢‘
        let composition = AVMutableComposition()
        let audioTrack = composition.addMutableTrack(withMediaType: .audio, preferredTrackID: kCMPersistentTrackID_Invalid)
        
        var currentTime = CMTime.zero
        
        for url in tempURLs {
            let asset = AVAsset(url: url)
            let timeRange = CMTimeRange(start: .zero, duration: asset.duration)
            
            do {
                try audioTrack?.insertTimeRange(timeRange, of: asset.tracks(withMediaType: .audio)[0], at: currentTime)
                currentTime = CMTimeAdd(currentTime, asset.duration)
            } catch {
                logger.error("âŒ åˆå¹¶éŸ³é¢‘æ—¶å‡ºé”™: \(error.localizedDescription)")
                throw error
            }
        }
        
        // å¯¼å‡ºåˆå¹¶åçš„éŸ³é¢‘
        let outputURL = FileManager.default.temporaryDirectory.appendingPathComponent("combined.mp3")
        
        // åˆ é™¤å¯èƒ½å­˜åœ¨çš„æ—§æ–‡ä»¶
        try? FileManager.default.removeItem(at: outputURL)
        
        guard let exportSession = AVAssetExportSession(asset: composition, presetName: AVAssetExportPresetMediumQuality) else {
            throw NSError(domain: "com.example.baobao", code: -1, userInfo: [NSLocalizedDescriptionKey: "æ— æ³•åˆ›å»ºå¯¼å‡ºä¼šè¯"])
        }
        
        exportSession.outputURL = outputURL
        exportSession.outputFileType = .mp3
        
        // ç­‰å¾…å¯¼å‡ºå®Œæˆ
        let exportSemaphore = DispatchSemaphore(value: 0)
        exportSession.exportAsynchronously {
            exportSemaphore.signal()
        }
        exportSemaphore.wait()
        
        // æ£€æŸ¥å¯¼å‡ºçŠ¶æ€
        if exportSession.status == .completed {
            // è¯»å–åˆå¹¶çš„éŸ³é¢‘æ•°æ®
            let data = try Data(contentsOf: outputURL)
            
            // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            for url in tempURLs {
                try? FileManager.default.removeItem(at: url)
            }
            try? FileManager.default.removeItem(at: outputURL)
            
            return data
        } else {
            throw NSError(domain: "com.example.baobao", code: -1, userInfo: [NSLocalizedDescriptionKey: "å¯¼å‡ºå¤±è´¥: \(exportSession.error?.localizedDescription ?? "æœªçŸ¥é”™è¯¯")"])
        }
    }
    
    /// ç”ŸæˆSSMLæ ‡è®°
    /// - Parameters:
    ///   - text: æ–‡æœ¬å†…å®¹
    ///   - voiceType: è¯­éŸ³ç±»å‹
    ///   - speechRate: è¯­é€Ÿ
    /// - Returns: SSMLæ ‡è®°å­—ç¬¦ä¸²
    private func generateSSML(for text: String, voiceType: VoiceType, speechRate: SpeechRate) -> String {
        let escapedText = text
            .replacingOccurrences(of: "&", with: "&amp;")
            .replacingOccurrences(of: "<", with: "&lt;")
            .replacingOccurrences(of: ">", with: "&gt;")
            .replacingOccurrences(of: "\"", with: "&quot;")
            .replacingOccurrences(of: "'", with: "&apos;")
        
        // è·å–å®é™…çš„å£°éŸ³ID
        var voiceID = voiceType.rawValue
        if voiceType == .custom, let customVoiceID = ConfigurationManager.shared.getString(forKey: "CUSTOM_VOICE_ID", defaultValue: "").nilIfEmpty {
            voiceID = customVoiceID
        }
        
        // æ£€æŸ¥æ˜¯å¦éœ€è¦ä½¿ç”¨è‡ªå®šä¹‰å‘éŸ³
        let enableCustomPronunciation = ConfigurationManager.shared.getBool(forKey: "ENABLE_CUSTOM_PRONUNCIATION", defaultValue: true)
        
        // SSMLæ¨¡æ¿
        var ssml = """
        <speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xmlns:mstts="http://www.w3.org/2001/mstts" xml:lang="zh-CN">
            <voice name="\(voiceID)">
                <prosody rate="\(speechRate.value)">
        """
        
        // å¢å¼ºè¡¨ç°åŠ›
        if ConfigurationManager.shared.getBool(forKey: "ENHANCE_EXPRESSIVENESS", defaultValue: true) {
            ssml = ssml.replacingOccurrences(of: "<prosody rate", with: "<mstts:express-as style=\"cheerful\"><prosody rate")
        }
        
        // å¤„ç†æ–‡æœ¬æ·»åŠ æ ‡ç‚¹ã€åœé¡¿ç­‰
        if enableCustomPronunciation {
            ssml += enhanceTextWithPronunciation(escapedText)
        } else {
            ssml += escapedText
        }
        
        // å…³é—­æ ‡ç­¾
        if ConfigurationManager.shared.getBool(forKey: "ENHANCE_EXPRESSIVENESS", defaultValue: true) {
            ssml += """
                    </prosody>
                </mstts:express-as>
            </voice>
        </speak>
        """
        } else {
            ssml += """
                    </prosody>
                </voice>
            </speak>
            """
        }
        
        return ssml
    }
    
    /// å¢å¼ºæ–‡æœ¬çš„å‘éŸ³ï¼Œæ·»åŠ åœé¡¿å’Œè¯­è°ƒå˜åŒ–
    /// - Parameter text: åŸå§‹æ–‡æœ¬
    /// - Returns: å¢å¼ºåçš„æ–‡æœ¬
    private func enhanceTextWithPronunciation(_ text: String) -> String {
        var enhancedText = text
        
        // åœ¨é—®å·åæ·»åŠ å°åœé¡¿
        enhancedText = enhancedText.replacingOccurrences(of: "ï¼Ÿ", with: "ï¼Ÿ<break time=\"300ms\"/>")
        
        // åœ¨æ„Ÿå¹å·åæ·»åŠ ä¸­ç­‰åœé¡¿
        enhancedText = enhancedText.replacingOccurrences(of: "ï¼", with: "ï¼<break time=\"400ms\"/>")
        
        // åœ¨å¥å·åæ·»åŠ å°åœé¡¿
        enhancedText = enhancedText.replacingOccurrences(of: "ã€‚", with: "ã€‚<break time=\"250ms\"/>")
        
        // åœ¨é€—å·åæ·»åŠ æå°åœé¡¿
        enhancedText = enhancedText.replacingOccurrences(of: "ï¼Œ", with: "ï¼Œ<break time=\"150ms\"/>")
        
        // åœ¨åˆ†å·åæ·»åŠ å°åœé¡¿
        enhancedText = enhancedText.replacingOccurrences(of: "ï¼›", with: "ï¼›<break time=\"200ms\"/>")
        
        // åœ¨å†’å·åæ·»åŠ å°åœé¡¿
        enhancedText = enhancedText.replacingOccurrences(of: "ï¼š", with: "ï¼š<break time=\"200ms\"/>")
        
        // å¤„ç†å¼•å·ä¸­çš„æ–‡æœ¬ï¼Œå¢åŠ è¯­è°ƒå˜åŒ–ï¼ˆè¡¨ç¤ºå¯¹è¯ï¼‰
        var components = enhancedText.components(separatedBy: """)
        if components.count > 1 {
            for i in 1..<components.count {
                if let endQuoteIndex = components[i].firstIndex(of: """) {
                    let dialogText = String(components[i][..<endQuoteIndex])
                    let wrappedDialog = "<prosody pitch=\"+10%\">\(dialogText)</prosody>"
                    
                    let afterQuote = String(components[i][endQuoteIndex...])
                    components[i] = wrappedDialog + afterQuote
                }
            }
            enhancedText = components.joined(separator: """)
        }
        
        return enhancedText
    }
    
    /// å‘é€Azureè¯­éŸ³åˆæˆè¯·æ±‚
    /// - Parameters:
    ///   - ssml: SSMLæ ‡è®°
    ///   - completion: å®Œæˆå›è°ƒ
    private func makeAzureSpeechRequest(ssml: String, completion: @escaping (Result<Data, Error>) -> Void) {
        // è·å–APIé…ç½®
        guard let subscriptionKey = ConfigurationManager.shared.getString(forKey: "AZURE_SPEECH_KEY", defaultValue: "").nilIfEmpty,
              let region = ConfigurationManager.shared.getString(forKey: "AZURE_SPEECH_REGION", defaultValue: "eastasia").nilIfEmpty else {
            completion(.failure(NSError(domain: "com.example.baobao", code: -1, userInfo: [NSLocalizedDescriptionKey: "Azureè¯­éŸ³é…ç½®ç¼ºå¤±"])))
            return
        }
        
        // æ„å»ºAPI URL
        let urlString = "https://\(region).tts.speech.microsoft.com/cognitiveservices/v1"
        guard let url = URL(string: urlString) else {
            completion(.failure(NSError(domain: "com.example.baobao", code: -1, userInfo: [NSLocalizedDescriptionKey: "æ— æ•ˆçš„Azure API URL"])))
            return
        }
        
        // åˆ›å»ºè¯·æ±‚
        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.addValue(subscriptionKey, forHTTPHeaderField: "Ocp-Apim-Subscription-Key")
        request.addValue("application/ssml+xml", forHTTPHeaderField: "Content-Type")
        request.addValue("audio-16khz-128kbitrate-mono-mp3", forHTTPHeaderField: "X-Microsoft-OutputFormat")
        request.addValue(UUID().uuidString, forHTTPHeaderField: "X-RequestId")
        request.httpBody = ssml.data(using: .utf8)
        
        // è®°å½•å¼€å§‹æ—¶é—´
        let startTime = Date()
        
        // å‘é€è¯·æ±‚
        let task = URLSession.shared.dataTask(with: request) { [weak self] data, response, error in
            guard let self = self else { return }
            
            // è®¡ç®—è¯·æ±‚æ—¶é—´
            let requestTime = Date().timeIntervalSince(startTime)
            self.logger.info("â±ï¸ è¯­éŸ³åˆæˆè¯·æ±‚è€—æ—¶: \(String(format: "%.2f", requestTime))ç§’")
            
            // å¤„ç†é”™è¯¯
            if let error = error {
                self.logger.error("âŒ ç½‘ç»œé”™è¯¯: \(error.localizedDescription)")
                completion(.failure(error))
                return
            }
            
            // æ£€æŸ¥HTTPå“åº”
            guard let httpResponse = response as? HTTPURLResponse else {
                completion(.failure(NSError(domain: "com.example.baobao", code: -1, userInfo: [NSLocalizedDescriptionKey: "æ— æ•ˆçš„HTTPå“åº”"])))
                return
            }
            
            // æ£€æŸ¥çŠ¶æ€ç 
            guard httpResponse.statusCode == 200 else {
                let errorMessage = String(data: data ?? Data(), encoding: .utf8) ?? "æœªçŸ¥é”™è¯¯"
                self.logger.error("âŒ Azure APIé”™è¯¯ (\(httpResponse.statusCode)): \(errorMessage)")
                completion(.failure(NSError(domain: "com.example.baobao", code: httpResponse.statusCode, userInfo: [NSLocalizedDescriptionKey: "AzureæœåŠ¡é”™è¯¯: \(errorMessage)"])))
                return
            }
            
            // æ£€æŸ¥æ•°æ®
            guard let data = data, !data.isEmpty else {
                completion(.failure(NSError(domain: "com.example.baobao", code: -1, userInfo: [NSLocalizedDescriptionKey: "è¿”å›æ•°æ®ä¸ºç©º"])))
                return
            }
            
            // è®°å½•éŸ³é¢‘å¤§å°
            self.logger.info("ğŸ“Š åˆæˆçš„éŸ³é¢‘å¤§å°: \(String(format: "%.2f", Double(data.count) / 1024.0))KB")
            
            // è¿”å›æˆåŠŸç»“æœ
            completion(.success(data))
        }
        
        // ä¿å­˜ä»»åŠ¡å¼•ç”¨
        currentSynthesisTask = task
        
        // å¯åŠ¨ä»»åŠ¡
        task.resume()
    }
    
    /// ä¿å­˜éŸ³é¢‘æ•°æ®åˆ°ä¸´æ—¶æ–‡ä»¶
    /// - Parameter data: éŸ³é¢‘æ•°æ®
    /// - Returns: ä¸´æ—¶æ–‡ä»¶URL
    private func saveToTempFile(data: Data) throws -> URL {
        // åˆ›å»ºå”¯ä¸€æ–‡ä»¶å
        let fileName = "speech_\(UUID().uuidString).mp3"
        let fileURL = FileManager.default.temporaryDirectory.appendingPathComponent(fileName)
        
        // ä¿å­˜æ•°æ®
        try data.write(to: fileURL)
        
        return fileURL
    }
    
    // MARK: - éŸ³é¢‘æ’­æ”¾
    
    /// æ’­æ”¾éŸ³é¢‘
    /// - Parameters:
    ///   - url: éŸ³é¢‘æ–‡ä»¶URL
    ///   - position: èµ·å§‹ä½ç½®ï¼ˆç§’ï¼‰
    ///   - progressHandler: æ’­æ”¾è¿›åº¦å¤„ç†å™¨
    ///   - completion: å®Œæˆå›è°ƒï¼Œè¿”å›å¯èƒ½çš„é”™è¯¯
    func play(url: URL, from position: TimeInterval = 0, progressHandler: ((TimeInterval) -> Void)? = nil, completion: @escaping (Error?) -> Void) {
        logger.info("â–¶ï¸ å¼€å§‹æ’­æ”¾éŸ³é¢‘: \(url.lastPathComponent)")
        
        do {
            try configureAudioSession()
            
            // åˆ›å»ºéŸ³é¢‘æ’­æ”¾å™¨
            audioPlayer = try AVAudioPlayer(contentsOf: url)
            audioPlayer?.delegate = self
            audioPlayer?.currentTime = position
            audioPlayer?.prepareToPlay()
            
            // è®¾ç½®è¿›åº¦æ›´æ–°å¤„ç†å™¨
            self.playbackUpdateHandler = progressHandler
            
            // å¼€å§‹æ’­æ”¾
            if audioPlayer?.play() == true {
                startPlaybackTimer()
                logger.info("âœ… éŸ³é¢‘å¼€å§‹æ’­æ”¾ï¼Œä»ä½ç½®: \(position)ç§’")
                completion(nil)
            } else {
                let error = NSError(domain: "com.example.baobao", code: -1, userInfo: [NSLocalizedDescriptionKey: "æ’­æ”¾å¤±è´¥"])
                logger.error("âŒ éŸ³é¢‘æ’­æ”¾å¤±è´¥")
                completion(error)
            }
        } catch {
            logger.error("âŒ åˆ›å»ºéŸ³é¢‘æ’­æ”¾å™¨å¤±è´¥: \(error.localizedDescription)")
            completion(error)
        }
    }
    
    /// åœæ­¢æ’­æ”¾
    func stop() {
        logger.info("â¹ï¸ åœæ­¢æ’­æ”¾éŸ³é¢‘")
        stopPlaybackTimer()
        audioPlayer?.stop()
        audioPlayer = nil
        currentPlaybackTime = 0
    }
    
    /// æš‚åœæ’­æ”¾
    func pause() {
        logger.info("â¸ï¸ æš‚åœæ’­æ”¾éŸ³é¢‘")
        stopPlaybackTimer()
        audioPlayer?.pause()
    }
    
    /// æ¢å¤æ’­æ”¾
    func resume() {
        logger.info("â–¶ï¸ æ¢å¤æ’­æ”¾éŸ³é¢‘")
        if audioPlayer?.play() == true {
            startPlaybackTimer()
        }
    }
    
    /// è·å–å½“å‰æ’­æ”¾æ—¶é—´
    /// - Returns: å½“å‰æ’­æ”¾æ—¶é—´ï¼ˆç§’ï¼‰
    func getCurrentTime() -> TimeInterval {
        return audioPlayer?.currentTime ?? 0
    }
    
    /// è·å–éŸ³é¢‘æ€»æ—¶é•¿
    /// - Returns: éŸ³é¢‘æ€»æ—¶é•¿ï¼ˆç§’ï¼‰
    func getDuration() -> TimeInterval {
        return audioPlayer?.duration ?? 0
    }
    
    // MARK: - ç¼“å­˜ç®¡ç†
    
    /// æ¸…ç†è¯­éŸ³ç¼“å­˜
    func clearCache() {
        logger.info("ğŸ§¹ æ¸…ç†éŸ³é¢‘ç¼“å­˜")
        
        let fileManager = FileManager.default
        let tempDirectory = fileManager.temporaryDirectory
        
        do {
            // æ¸…ç†ä¸´æ—¶ç›®å½•
            let tempFiles = try fileManager.contentsOfDirectory(at: tempDirectory,
                                                             includingPropertiesForKeys: nil,
                                                             options: [])
            
            for file in tempFiles where file.lastPathComponent.hasPrefix("speech_") {
                try fileManager.removeItem(at: file)
            }
            
            // æ¸…ç†æŒä¹…åŒ–å­˜å‚¨ä¸­çš„è¿‡æœŸæ–‡ä»¶
            let documentsURL = fileManager.urls(for: .documentDirectory, in: .userDomainMask)[0]
            let documentFiles = try fileManager.contentsOfDirectory(at: documentsURL,
                                                                 includingPropertiesForKeys: [.creationDateKey],
                                                                 options: [])
            
            // ä½¿ç”¨é…ç½®çš„ç¼“å­˜è¿‡æœŸå¤©æ•°
            let expiryDate = Date().addingTimeInterval(-Double(cacheExpiryDays) * 24 * 60 * 60)
            
            for file in documentFiles where file.lastPathComponent.hasPrefix("speech_") {
                if let attributes = try? fileManager.attributesOfItem(atPath: file.path),
                   let creationDate = attributes[.creationDate] as? Date,
                   creationDate < expiryDate {
                    try fileManager.removeItem(at: file)
                }
            }
            
            logger.info("âœ… ç¼“å­˜æ¸…ç†å®Œæˆ")
        } catch {
            logger.error("âŒ æ¸…ç†ç¼“å­˜å¤±è´¥: \(error.localizedDescription)")
        }
    }
    
    // MARK: - è¾…åŠ©æ–¹æ³•
    
    /// é…ç½®æœ¬åœ°è¯­éŸ³å‚æ•°
    /// - Parameters:
    ///   - utterance: è¯­éŸ³åˆæˆè¯·æ±‚
    ///   - voiceType: è¯­éŸ³ç±»å‹
    private func configureLocalUtterance(_ utterance: AVSpeechUtterance, voiceType: String) {
        // æ ¹æ®æ˜¾ç¤ºåç§°è®¾ç½®è¯­éŸ³å‚æ•°
        switch voiceType {
        case "èèé˜¿å§¨":
            utterance.voice = AVSpeechSynthesisVoice(language: "zh-CN")
            utterance.rate = 0.5
            utterance.pitchMultiplier = 1.1
        case "å¤§å«å”å”":
            utterance.voice = AVSpeechSynthesisVoice(language: "zh-CN")
            utterance.rate = 0.45
            utterance.pitchMultiplier = 0.9
        case "æ•…äº‹çˆ·çˆ·":
            utterance.voice = AVSpeechSynthesisVoice(language: "zh-CN")
            utterance.rate = 0.4
            utterance.pitchMultiplier = 0.85
        case "ç”œç”œå§å§":
            utterance.voice = AVSpeechSynthesisVoice(language: "zh-CN")
            utterance.rate = 0.5
            utterance.pitchMultiplier = 1.2
        case "æ´»æ³¼ç«¥å£°":
            utterance.voice = AVSpeechSynthesisVoice(language: "zh-CN")
            utterance.rate = 0.55
            utterance.pitchMultiplier = 1.3
        default:
            utterance.voice = AVSpeechSynthesisVoice(language: "zh-CN")
            utterance.rate = 0.5
            utterance.pitchMultiplier = 1.0
        }
        
        utterance.volume = 1.0
    }
    
    /// é…ç½®éŸ³é¢‘ä¼šè¯
    /// - Throws: é…ç½®éŸ³é¢‘ä¼šè¯æ—¶çš„é”™è¯¯
    private func configureAudioSession() throws {
        try AVAudioSession.sharedInstance().setCategory(.playback, mode: .default)
        try AVAudioSession.sharedInstance().setActive(true)
    }
    
    /// å¼€å§‹æ’­æ”¾è®¡æ—¶å™¨
    private func startPlaybackTimer() {
        stopPlaybackTimer()
        playbackTimer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { [weak self] _ in
            guard let self = self,
                  let player = self.audioPlayer,
                  player.isPlaying else {
                return
            }
            
            self.currentPlaybackTime = player.currentTime
            self.playbackUpdateHandler?(self.currentPlaybackTime)
        }
    }
    
    /// åœæ­¢æ’­æ”¾è®¡æ—¶å™¨
    private func stopPlaybackTimer() {
        playbackTimer?.invalidate()
        playbackTimer = nil
    }
}

// MARK: - AVAudioPlayerDelegate

extension SpeechService: AVAudioPlayerDelegate {
    func audioPlayerDidFinishPlaying(_ player: AVAudioPlayer, successfully flag: Bool) {
        logger.info("ğŸ éŸ³é¢‘æ’­æ”¾ç»“æŸï¼ŒæˆåŠŸ: \(flag)")
        stopPlaybackTimer()
        audioPlayer = nil
        currentPlaybackTime = 0
    }
    
    func audioPlayerDecodeErrorDidOccur(_ player: AVAudioPlayer, error: Error?) {
        if let error = error {
            logger.error("âŒ éŸ³é¢‘è§£ç é”™è¯¯: \(error.localizedDescription)")
        }
        stopPlaybackTimer()
        audioPlayer = nil
        currentPlaybackTime = 0
    }
}

// MARK: - å­—ç¬¦ä¸²æ‰©å±•
extension String {
    /// å¦‚æœå­—ç¬¦ä¸²ä¸ºç©ºåˆ™è¿”å›nil
    var nilIfEmpty: String? {
        return isEmpty ? nil : self
    }
} 